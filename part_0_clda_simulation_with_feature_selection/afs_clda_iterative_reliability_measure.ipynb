{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:37.983959Z",
     "start_time": "2021-08-25T01:06:37.981341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o feature selection\n",
      "w/ iter feature selection\n",
      "w/o start with high SNR neurons\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for comparision\n",
    "exp_conds = ['w/o feature selection', \n",
    "             'w/ iter feature selection',\n",
    "            'w/o start with high SNR neurons']\n",
    "\n",
    "for e in exp_conds: print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental setup related to the questions\n",
    "\n",
    "this part should be configured to directly test the hypothesis put forward in the previous section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.029500Z",
     "start_time": "2021-08-25T01:06:37.985225Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "mean_firing_rate_low = 50\n",
    "mean_firing_rate_high = 200\n",
    "noise_mode = 'fixed_gaussian'\n",
    "fixed_noise_level = 5 #Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.034532Z",
     "start_time": "2021-08-25T01:06:38.030571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have two types of indices: \n",
      "noisy:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "non_noisy:[24 25 26 27 28 29 30 31]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "neuron_types = ['noisy', 'non_noisy']\n",
    "\n",
    "n_neurons = 32\n",
    "n_neurons_noisy_group = 24\n",
    "n_neurons_no_noise_group = 8\n",
    "\n",
    "\n",
    "noise_neuron_ind = np.arange(n_neurons_noisy_group)\n",
    "no_noise_neuron_ind = np.arange(n_neurons_noisy_group, n_neurons_noisy_group + n_neurons_no_noise_group)\n",
    "\n",
    "neuron_type_indices_in_a_list = [\n",
    "    noise_neuron_ind, \n",
    "    no_noise_neuron_ind\n",
    "]\n",
    "\n",
    "\n",
    "noise_neuron_list = np.full(n_neurons, False, dtype = bool)\n",
    "no_noise_neuron_list = np.full(n_neurons, False, dtype = bool)\n",
    "\n",
    "\n",
    "noise_neuron_list[noise_neuron_ind] = True\n",
    "no_noise_neuron_list[no_noise_neuron_ind] = True\n",
    "\n",
    "\n",
    "\n",
    "neuron_type_bool_list = [\n",
    "    noise_neuron_list,\n",
    "    no_noise_neuron_list,\n",
    "]\n",
    "\n",
    "N_TYPES_OF_NEURONS = 2\n",
    "\n",
    "print('We have two types of indices: ')\n",
    "for t,l in enumerate(neuron_type_indices_in_a_list): print(f'{neuron_types[t]}:{l}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.038675Z",
     "start_time": "2021-08-25T01:06:38.035568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up the variances in a list:\n",
      "we therefore know the number of neurons to be 32\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "percent_of_count = np.ones(n_neurons)[:, np.newaxis]\n",
    "print(f'set up the variances in a list:')\n",
    "\n",
    "percent_of_count[noise_neuron_ind] =  1\n",
    "percent_of_count[no_noise_neuron_ind] = 1\n",
    "\n",
    "print(f'we therefore know the number of neurons to be {n_neurons}')\n",
    "print(percent_of_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.041540Z",
     "start_time": "2021-08-25T01:06:38.039784Z"
    }
   },
   "outputs": [],
   "source": [
    "# CHANGE: game mechanics: generate task params\n",
    "N_TARGETS = 8\n",
    "N_TRIALS = 200\n",
    "\n",
    "NUM_EXP = len(exp_conds) # how many experiments we are running. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config the experiments\n",
    "\n",
    "this section largely copyied and pasted from   \n",
    "bmi3d-sijia(branch)-bulti_in_experiemnts\n",
    "https://github.com/sijia66/brain-python-interface/blob/master/built_in_tasks/sim_task_KF.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dependant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.044429Z",
     "start_time": "2021-08-25T01:06:38.042775Z"
    }
   },
   "outputs": [],
   "source": [
    "GLOBAL_FIGURE_VERTICAL_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.052723Z",
     "start_time": "2021-08-25T01:06:38.046109Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (bmimultitasks.py, line 935)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/sijia-aw/BMi3D_my/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3417\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-b9a7c0293725>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from bmimultitasks import SimBMIControlMulti, SimBMICosEncKFDec, BMIControlMultiNoWindow\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/sijia-aw/BMi3D_my/lab_bmi3d/built_in_tasks/bmimultitasks.py\"\u001b[0;36m, line \u001b[0;32m935\u001b[0m\n\u001b[0;31m    class BMIControlMultiNoWindow(BMILoop, LinearlyDecreasingAssist, ConcreteTargetCapture):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "# make sure these directories are in the python path., \n",
    "from bmimultitasks import SimBMIControlMulti, SimBMICosEncKFDec, BMIControlMultiNoWindow\n",
    "from features import SaveHDF\n",
    "from features.simulation_features import get_enc_setup, SimKFDecoderRandom,SimIntentionLQRController, SimClockTick\n",
    "from features.simulation_features import SimHDF, SimTime\n",
    "\n",
    "from riglib import experiment\n",
    "\n",
    "from riglib.stereo_opengl.window import FakeWindow\n",
    "from riglib.bmi import train\n",
    "\n",
    "\n",
    "from behaviour_metrics import  filter_state, sort_trials\n",
    "\n",
    "from weights import calc_p_values_for_spike_batches_use_intended_kin\n",
    "from weights import calc_single_batch_p_values_by_fitting_kinematics_to_spike_counts\n",
    "import weights\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import itertools #for identical sequences\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  behaviour and task setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.054309Z",
     "start_time": "2021-08-25T01:06:37.982Z"
    }
   },
   "outputs": [],
   "source": [
    "seq = SimBMIControlMulti.sim_target_seq_generator_multi(\n",
    "N_TARGETS, N_TRIALS)\n",
    "\n",
    "#create a second version of the tasks\n",
    "seqs = itertools.tee(seq, NUM_EXP + 1)\n",
    "target_seq = list(seqs[NUM_EXP])\n",
    "\n",
    "seqs = seqs[:NUM_EXP]\n",
    "\n",
    "\n",
    "SAVE_HDF = False\n",
    "SAVE_SIM_HDF = True #this makes the task data available as exp.task_data_hist\n",
    "DEBUG_FEATURE = False\n",
    "\n",
    "\n",
    "#base_class = SimBMIControlMulti\n",
    "base_class = BMIControlMultiNoWindow\n",
    "\n",
    "#for adding experimental features such as encoder, decoder\n",
    "feats = []\n",
    "feats_2 = []\n",
    "feats_set = [] # this is a going to be a list of lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.054970Z",
     "start_time": "2021-08-25T01:06:37.984Z"
    }
   },
   "outputs": [],
   "source": [
    "from simulation_features import TimeCountDown\n",
    "\n",
    "feats.append(TimeCountDown)\n",
    "feats_2.append(TimeCountDown)\n",
    "\n",
    "total_exp_time = 600# in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.055643Z",
     "start_time": "2021-08-25T01:06:37.985Z"
    }
   },
   "outputs": [],
   "source": [
    "#from features.sync_features import NIDAQSync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder\n",
    "\n",
    "the cosine tuned encoder uses a poisson process, right\n",
    "https://en.wikipedia.org/wiki/Poisson_distribution\n",
    "so if the lambda is 1, then it's very likely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.056325Z",
     "start_time": "2021-08-25T01:06:37.988Z"
    }
   },
   "outputs": [],
   "source": [
    "from features.simulation_features import get_enc_setup\n",
    "\n",
    "ENCODER_TYPE = 'cosine_tuned_encoder_with_poisson_noise'\n",
    "\n",
    "#neuron set up : 'std (20 neurons)' or 'toy (4 neurons)' \n",
    "N_NEURONS, N_STATES, sim_C = get_enc_setup(sim_mode = 'rot_90', n_neurons= n_neurons)\n",
    "\n",
    "\n",
    "print(no_noise_neuron_list)\n",
    "#multiply our the neurons\n",
    "sim_C[noise_neuron_list] =  sim_C[noise_neuron_list]  * mean_firing_rate_low\n",
    "sim_C[no_noise_neuron_list]  = sim_C[no_noise_neuron_list] * mean_firing_rate_high\n",
    "\n",
    "\n",
    "print(sim_C)\n",
    "\n",
    "#set up intention feedbackcontroller\n",
    "#this ideally set before the encoder\n",
    "feats.append(SimIntentionLQRController)\n",
    "\n",
    "#set up the encoder\n",
    "from features.simulation_features import SimCosineTunedEncWithNoise\n",
    "feats.append(SimCosineTunedEncWithNoise)\n",
    "\n",
    "\n",
    "feats_2.append(SimIntentionLQRController)\n",
    "feats_2.append(SimCosineTunedEncWithNoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.056997Z",
     "start_time": "2021-08-25T01:06:37.990Z"
    }
   },
   "outputs": [],
   "source": [
    "#clda on random \n",
    "DECODER_MODE = 'random' # random \n",
    "\n",
    "   #take care the decoder setup\n",
    "if DECODER_MODE == 'random':\n",
    "    feats.append(SimKFDecoderRandom)\n",
    "    feats_2.append(SimKFDecoderRandom)\n",
    "    print(f'{__name__}: set base class ')\n",
    "    print(f'{__name__}: selected SimKFDecoderRandom \\n')\n",
    "else: #defaul to a cosEnc and a pre-traind KF DEC\n",
    "    from features.simulation_features import SimKFDecoderSup\n",
    "    feats.append(SimKFDecoderSup)\n",
    "    feats_2.append(SimKFDecoderRandom)\n",
    "    print(f'{__name__}: set decoder to SimKFDecoderSup\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  clda: learner and updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.057672Z",
     "start_time": "2021-08-25T01:06:37.992Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#setting clda parameters \n",
    "##learner: collects paird data at batch_sizes\n",
    "RHO = 0.01\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "#learner and updater: actualy set up rho\n",
    "UPDATER_BATCH_TIME = 1\n",
    "UPDATER_HALF_LIFE = np.log(RHO)  * UPDATER_BATCH_TIME / np.log(0.5)\n",
    "\n",
    "\n",
    "\n",
    "LEARNER_TYPE = 'feedback' # to dumb or not dumb it is a question 'feedback'\n",
    "UPDATER_TYPE = 'smooth_batch' #none or \"smooth_batch\"\n",
    "\n",
    "\n",
    "#you know what? \n",
    "#learner only collects firing rates labeled with estimated estimates\n",
    "#we would also need to use the labeled data\n",
    "#now, we can set up a dumb/or not-dumb learner\n",
    "if LEARNER_TYPE == 'feedback':\n",
    "    from features.simulation_features import SimFeedbackLearner\n",
    "    feats.append(SimFeedbackLearner)\n",
    "    feats_2.append(SimFeedbackLearner)\n",
    "else:\n",
    "    from features.simulation_features import SimDumbLearner\n",
    "    feats.append(SimDumbLearner)\n",
    "    feats_2.append(SimDumbLearner)\n",
    "\n",
    "#to update the decoder.\n",
    "if UPDATER_TYPE == 'smooth_batch':\n",
    "    from features.simulation_features import SimSmoothBatch\n",
    "    feats.append(SimSmoothBatch)\n",
    "    feats_2.append(SimSmoothBatch)\n",
    "else: #defaut to none \n",
    "    print(f'{__name__}: need to specify an updater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selector setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.058340Z",
     "start_time": "2021-08-25T01:06:37.994Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature_selection_feature import FeatureTransformer, TransformerBatchToFit\n",
    "from feature_selection_feature import FeatureSelector, LassoFeatureSelector, SNRFeatureSelector, IterativeFeatureSelector\n",
    "from feature_selection_feature import ReliabilityFeatureSelector\n",
    "\n",
    "\n",
    "#pass the real time limit on clock\n",
    "feats.append(FeatureSelector)\n",
    "feats_2.append(ReliabilityFeatureSelector)\n",
    "\n",
    "\n",
    "feature_x_meth_arg = [\n",
    "    ('transpose', None ),\n",
    "]\n",
    "\n",
    "kwargs_feature = dict()\n",
    "kwargs_feature = {\n",
    "    'transform_x_flag':True,\n",
    "    'transform_y_flag':True,\n",
    "    'feature_x_transformer':FeatureTransformer(feature_x_meth_arg),\n",
    "    'feature_y_transformer':TransformerBatchToFit(),\n",
    "    'n_starting_feats': n_neurons,\n",
    "    'n_states':  7\n",
    "}\n",
    "\n",
    "print('kwargs will be updated in a later time')\n",
    "print(f'the feature adaptation project is tracking {kwargs_feature.keys()} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assistor setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.059002Z",
     "start_time": "2021-08-25T01:06:37.996Z"
    }
   },
   "outputs": [],
   "source": [
    "#assistor set up assist level\n",
    "assist_level = (0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Check) config the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.059683Z",
     "start_time": "2021-08-25T01:06:37.998Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_feats = [feats, feats_2, feats]\n",
    "exp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.060386Z",
     "start_time": "2021-08-25T01:06:38.000Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG_FEATURE: \n",
    "    from features.simulation_features import DebugFeature\n",
    "    feats.append(DebugFeature)\n",
    "    \n",
    "if SAVE_HDF: \n",
    "    feats.append(SaveHDF)\n",
    "    feats_2.append(SaveHDF)\n",
    "if SAVE_SIM_HDF: \n",
    "    feats.append(SimHDF)\n",
    "    feats_2.append(SimHDF)\n",
    "    \n",
    "    \n",
    "#pass the real time limit on clock\n",
    "feats.append(SimClockTick)\n",
    "feats.append(SimTime)\n",
    "\n",
    "feats_2.append(SimClockTick)\n",
    "feats_2.append(SimTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.061075Z",
     "start_time": "2021-08-25T01:06:38.001Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs_exps = list()\n",
    "\n",
    "for i in range(NUM_EXP):\n",
    "    d = dict()\n",
    "    \n",
    "    d['total_exp_time'] = total_exp_time\n",
    "    \n",
    "    d['assist_level'] = assist_level\n",
    "    d['sim_C'] = sim_C\n",
    "    \n",
    "    d['noise_mode'] = noise_mode\n",
    "    d['percent_noise'] = percent_of_count\n",
    "    d['fixed_noise_level'] = fixed_noise_level\n",
    "    \n",
    "    d['batch_size'] = batch_size\n",
    "    \n",
    "    d['batch_time'] = UPDATER_BATCH_TIME\n",
    "    d['half_life'] = UPDATER_HALF_LIFE\n",
    "    \n",
    "    \n",
    "    d.update(kwargs_feature)\n",
    "    \n",
    "    kwargs_exps.append(d)\n",
    "\n",
    "kwargs_exps[1]['init_feat_set'] = np.full(N_NEURONS, True, dtype = bool)\n",
    "\n",
    "\n",
    "kwargs_exps[2]['init_feat_set'] = np.full(N_NEURONS, False, dtype = bool)\n",
    "kwargs_exps[2]['init_feat_set'][no_noise_neuron_list] = True\n",
    "\n",
    "print(f'we have got {len(kwargs_exps)} exps')\n",
    "kwargs_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make and initalize experiment instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.061752Z",
     "start_time": "2021-08-25T01:06:38.003Z"
    }
   },
   "outputs": [],
   "source": [
    "#seed the experiment\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "exps = list()#create a list of experiment\n",
    "\n",
    "for i,s in enumerate(seqs):\n",
    "    #spawn the task\n",
    "    f = exp_feats[i]\n",
    "    Exp = experiment.make(base_class, feats=f)\n",
    "    \n",
    "    e = Exp(s, **kwargs_exps[i])\n",
    "    exps.append(e)\n",
    "\n",
    "\n",
    "exps_np  = np.array(exps, dtype = 'object')\n",
    "    \n",
    "#run the ini\n",
    "for e in exps_np: \n",
    "    e.init()\n",
    "    print('next')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-experiment check: check the Kalman filter before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.062434Z",
     "start_time": "2021-08-25T01:06:38.005Z"
    }
   },
   "outputs": [],
   "source": [
    "from afs_plotting import plot_prefered_directions\n",
    "\n",
    "print('we replace the encoder using the weights')\n",
    "print('assume, they are all randomly initialized get the first decoder')\n",
    "\n",
    "first_decoder = exps_np[0].decoder\n",
    "target_C = first_decoder.filt.C\n",
    "target_Q = np.copy(first_decoder.filt.Q)\n",
    "\n",
    "print()\n",
    "diag_val = 10000\n",
    "np.fill_diagonal(target_Q, diag_val)\n",
    "\n",
    "    \n",
    "#replace the decoder\n",
    "for i,e in enumerate(exps):\n",
    "    weights.change_target_kalman_filter_with_a_C_mat(e.decoder.filt, target_C, \n",
    "                                                     Q= target_Q, debug=False)\n",
    "    e.select_decoder_features(e.decoder)\n",
    "    e.record_feature_active_set(e.decoder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.063115Z",
     "start_time": "2021-08-25T01:06:38.006Z"
    }
   },
   "outputs": [],
   "source": [
    "print('we check the new decoder C matrix:')\n",
    "\n",
    "figure_decoder_C, axs_decoder_C = plt.subplots(nrows=2, \n",
    "                               ncols=NUM_EXP, figsize = [GLOBAL_FIGURE_VERTICAL_SIZE * NUM_EXP, GLOBAL_FIGURE_VERTICAL_SIZE * 2],squeeze = False)\n",
    "figure_decoder_C.suptitle('KF C Matrix Before Training ')\n",
    "\n",
    "for i,e in enumerate(exps):\n",
    "    C = e.decoder.filt.C\n",
    "    plot_prefered_directions(C, ax = axs_decoder_C[0,i])\n",
    "    axs_decoder_C[0,i].set_title(exp_conds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment run: assemble into a complete loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actually running the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.063790Z",
     "start_time": "2021-08-25T01:06:38.009Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from feature_selection_feature import run_exp_loop\n",
    "for i,e in enumerate(exps):\n",
    "    np.random.seed(0)\n",
    "    run_exp_loop(e, **kwargs_exps[i])\n",
    "    print(f'Finished running  {exp_conds[i]}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T01:00:26.027506Z",
     "start_time": "2021-01-25T01:00:26.024320Z"
    }
   },
   "source": [
    "# Postprocessing the data for loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## declare defs and conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.064457Z",
     "start_time": "2021-08-25T01:06:38.010Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature_selection_feature import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.065126Z",
     "start_time": "2021-08-25T01:06:38.012Z"
    }
   },
   "outputs": [],
   "source": [
    "task_data_hist_np_all = [np.array(e.task_data_hist) for e in exps]\n",
    "len(task_data_hist_np_all)\n",
    "task_data_hist_np_all[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished time in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.065791Z",
     "start_time": "2021-08-25T01:06:38.013Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total finished trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.066468Z",
     "start_time": "2021-08-25T01:06:38.015Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculate how many trials\n",
    "for e in  exps: print(e.calc_state_occurrences('reward'))\n",
    "print()\n",
    "\n",
    "for e in  exps: print(e.calc_trial_num())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall  trial statistics succuss rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.067142Z",
     "start_time": "2021-08-25T01:06:38.016Z"
    }
   },
   "outputs": [],
   "source": [
    "import behaviour_metrics\n",
    "import importlib\n",
    "\n",
    "sns.set_context(context = 'talk')\n",
    "importlib.reload(behaviour_metrics)\n",
    "\n",
    "reward_events_per_minute = [behaviour_metrics.calc_event_rate_from_state_log(e.state_log,'reward',window_length=30) for e in exps]\n",
    "reward_events_per_minute = np.array(reward_events_per_minute)\n",
    "\n",
    "print(reward_events_per_minute)\n",
    "plt.plot(reward_events_per_minute.T)\n",
    "plt.legend(exp_conds, bbox_to_anchor=(1, -0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort into trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.067806Z",
     "start_time": "2021-08-25T01:06:38.018Z"
    }
   },
   "outputs": [],
   "source": [
    "state_log = e.state_log\n",
    "segmented_trials = behaviour_metrics.segment_trials_in_state_log(state_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.068476Z",
     "start_time": "2021-08-25T01:06:38.019Z"
    }
   },
   "outputs": [],
   "source": [
    "trial_dicts_all = []\n",
    "dict_keys = ['cursor', #behaviour\n",
    "             'ctrl_input', 'spike_counts', #encoder translates intended ctrl into spike counts\n",
    "             'decoder_state']\n",
    "\n",
    "\n",
    "for i in range(NUM_EXP):\n",
    "    \n",
    "    segmented_trials = behaviour_metrics.segment_trials_in_state_log(exps[i].state_log)\n",
    "\n",
    "    task_data_hist_np = task_data_hist_np_all[i]\n",
    "    trial_dict_0 = behaviour_metrics.sort_trials_use_segmented_log(segmented_trials, \n",
    "                               target_seq,\n",
    "                               task_data_hist_np, dict_keys)\n",
    "    \n",
    "    trial_dicts_all.append(trial_dict_0)\n",
    "\n",
    "for t in trial_dicts_all: print(len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behaviour  analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.069143Z",
     "start_time": "2021-08-25T01:06:38.021Z"
    }
   },
   "outputs": [],
   "source": [
    "import afs_plotting\n",
    "importlib.reload(afs_plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.069807Z",
     "start_time": "2021-08-25T01:06:38.022Z"
    }
   },
   "outputs": [],
   "source": [
    "figure_trajectory, axes_trajectory = plt.subplots(1, NUM_EXP, figsize = (NUM_EXP * GLOBAL_FIGURE_VERTICAL_SIZE, \n",
    "                                                  GLOBAL_FIGURE_VERTICAL_SIZE)) \n",
    "\n",
    "\n",
    "n_roi_trials = 0\n",
    "\n",
    "CIRCLE_RADIUS = exps[0].target_radius\n",
    "\n",
    "print(CIRCLE_RADIUS)\n",
    "\n",
    "for i,axes in enumerate(axes_trajectory): \n",
    "\n",
    "    afs_plotting.add_center_out_grid(axes, target_seq, CIRCLE_RADIUS)\n",
    "    \n",
    "    \n",
    "    sample_trial = trial_dicts_all[i][n_roi_trials]\n",
    "    trial_cursor_trajectory = sample_trial['cursor']\n",
    "    \n",
    "    afs_plotting.plot_trial_trajectory(axes, trial_cursor_trajectory)\n",
    "\n",
    "    axes.set_title(f'Trial {N_TRIALS} of {exp_conds[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.070474Z",
     "start_time": "2021-08-25T01:06:38.024Z"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(behaviour_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.071132Z",
     "start_time": "2021-08-25T01:06:38.026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arc_length = [behaviour_metrics.calc_arc_length_from_trial_dict(trial_dict) for trial_dict in trial_dicts_all]\n",
    "for al in arc_length: plt.plot(al)\n",
    "plt.legend(exp_conds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder\n",
    "\n",
    "the job of the encoder is to directly encode intention into firing rates\n",
    "the direct measure is just pearson correlation coefficients between \n",
    "the intentions and the firing rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.071800Z",
     "start_time": "2021-08-25T01:06:38.028Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from afs_plotting import plot_prefered_directions\n",
    "\n",
    "TEXT_OFFSET_VERTICAL = -0.2\n",
    "\n",
    "\n",
    "figure_decoder_C.suptitle('KF C matrix before and after CLDA')\n",
    "\n",
    "print('steady state tuning curves:')\n",
    "\n",
    "for  i,e in enumerate(exps): \n",
    "\n",
    "    e = exps[i]\n",
    "    C = e.decoder.filt.C\n",
    "\n",
    "    plot_prefered_directions(C, ax = axs_decoder_C[1,i])\n",
    "    axs_decoder_C[1,i].set_title(f'{exp_conds[i]}')\n",
    "\n",
    "figure_decoder_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder compared to the encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.072460Z",
     "start_time": "2021-08-25T01:06:38.030Z"
    }
   },
   "outputs": [],
   "source": [
    "len(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.073132Z",
     "start_time": "2021-08-25T01:06:38.033Z"
    }
   },
   "outputs": [],
   "source": [
    "import convergence_analysis\n",
    "importlib.reload(convergence_analysis)\n",
    "from convergence_analysis import calc_cosine_sim_bet_two_matrices, calc_cosine_to_target_matrix\n",
    "\n",
    "active_feat_set = exps[2]._active_feat_set\n",
    "\n",
    "\n",
    "for i,e in enumerate(exps):\n",
    "    enc_directions = e.encoder.C\n",
    "    dec_directions = np.array(e._used_C_mat_list)\n",
    "    \n",
    "\n",
    "    angles_hist = calc_cosine_to_target_matrix( dec_directions,enc_directions)\n",
    "    \n",
    "    if i == 0:\n",
    "        active_angles = np.mean(angles_hist[:,noise_neuron_list], axis = 1)\n",
    "        plt.plot(active_angles)\n",
    "    \n",
    "    active_angles = np.mean(angles_hist[:,active_feat_set], axis = 1)\n",
    "    plt.plot(active_angles)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at K matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.073820Z",
     "start_time": "2021-08-25T01:06:38.035Z"
    }
   },
   "outputs": [],
   "source": [
    "figure_k_matrix, axes_k_matrix = plt.subplots(2,NUM_EXP,\n",
    "                                          figsize = (GLOBAL_FIGURE_VERTICAL_SIZE * NUM_EXP,\n",
    "                                                    GLOBAL_FIGURE_VERTICAL_SIZE * 2))\n",
    "\n",
    "for i,e in enumerate(exps):\n",
    "    K = (e._used_K_mat_list[1]).T\n",
    "\n",
    "    plot_prefered_directions(K, ax  = axes_k_matrix[0, i])\n",
    "    axes_k_matrix[0, i].set_title(exp_conds[i])\n",
    "\n",
    "for i,e in enumerate(exps):\n",
    "    K = (e._used_K_mat_list[-1]).T\n",
    "    plot_prefered_directions(K, ax  = axes_k_matrix[1, i])\n",
    "    axes_k_matrix[1,i].set_title(exp_conds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.074493Z",
     "start_time": "2021-08-25T01:06:38.037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "\n",
    "fig_feature_active_map, axes_feat_active_map = plt.subplots(1, NUM_EXP,\n",
    "                                                            figsize = ( NUM_EXP * GLOBAL_FIGURE_VERTICAL_SIZE,\n",
    "                                                                      GLOBAL_FIGURE_VERTICAL_SIZE),\n",
    "                                                           sharey = True)\n",
    "axes_feat_active_map[0].set_ylabel('Learner Batch number')\n",
    "\n",
    "#color true to yellow\n",
    "cmap = colors.ListedColormap(['yellow'])\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "\n",
    "    active_feat_heat_map = np.array(exp._active_feat_set_list, dtype = np.int32)\n",
    "    active_feat_heat_map = np.ma.masked_where(active_feat_heat_map == False, active_feat_heat_map)\n",
    "    a = axes_feat_active_map[i].imshow(active_feat_heat_map, cmap = cmap)\n",
    "\n",
    "    #color false to blue\n",
    "    cmap.set_bad(color='blue')\n",
    "    \n",
    "    axes_feat_active_map[i].set_xlabel('All features')\n",
    "    axes_feat_active_map[i].set_title(exp_conds[i])\n",
    "\n",
    "\n",
    "#fig_feature_active_map.colorbar(a, ax=axes_feat_active_map.ravel().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine used K mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examine used C mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.075157Z",
     "start_time": "2021-08-25T01:06:38.039Z"
    }
   },
   "outputs": [],
   "source": [
    "import weights_linear_regression\n",
    "importlib.reload(weights_linear_regression)\n",
    "from weights_linear_regression import calc_a_history_of_matrix_L2norms_along_first_axis\n",
    "\n",
    "\n",
    "figure_weights_norm, axes_weights_norm = plt.subplots( NUM_EXP, N_TYPES_OF_NEURONS,\n",
    "    figsize = (N_TYPES_OF_NEURONS * GLOBAL_FIGURE_VERTICAL_SIZE, NUM_EXP * GLOBAL_FIGURE_VERTICAL_SIZE))\n",
    "\n",
    "C_mat_all = list()\n",
    "\n",
    "for j,exp in enumerate(exps):\n",
    "    \n",
    "    updated_C_mat = np.array(exp._used_C_mat_list)\n",
    "    the_history_of_KF_weights_in_time_by_neurons = calc_a_history_of_matrix_L2norms_along_first_axis(updated_C_mat, debug = False)\n",
    "\n",
    "    C_mat_all.append(np.copy(updated_C_mat))\n",
    "    axe_exp = axes_weights_norm[j,:]\n",
    "    for i,a in enumerate(axe_exp):\n",
    "        a.plot(the_history_of_KF_weights_in_time_by_neurons[:, neuron_type_indices_in_a_list[i]])\n",
    "        a.set_xlabel('Batch number')\n",
    "        a.set_ylabel('Weight')\n",
    "        \n",
    "C_mat_all = np.array(C_mat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T01:06:38.075836Z",
     "start_time": "2021-08-25T01:06:38.041Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_compr_means, axes_compr_means = plt.subplots(1, N_TYPES_OF_NEURONS,\n",
    "                                                figsize = (GLOBAL_FIGURE_VERTICAL_SIZE * N_TYPES_OF_NEURONS,\n",
    "                                                          GLOBAL_FIGURE_VERTICAL_SIZE),\n",
    "                                                sharey = True)\n",
    "selected_feature_set = no_noise_neuron_list\n",
    "for i,a in enumerate(axes_compr_means):\n",
    "\n",
    "    type_neuron_list = neuron_type_bool_list[i]\n",
    "    \n",
    "    for C in C_mat_all:\n",
    "\n",
    "\n",
    "        the_history_of_KF_weights_in_time_by_neurons = calc_a_history_of_matrix_L2norms_along_first_axis(C, \n",
    "                                                                                                         target_C=e.encoder.C,\n",
    "                                                                indices_to_sum=(X_VEL_STATE_IND, Y_VEL_STATE_IND))\n",
    "\n",
    "\n",
    "        selected_neurons = np.logical_and(selected_feature_set, type_neuron_list)\n",
    "\n",
    "        selected_mean = np.mean(the_history_of_KF_weights_in_time_by_neurons[:,selected_neurons], axis = 1)\n",
    "        std = np.std(the_history_of_KF_weights_in_time_by_neurons[:,selected_neurons], axis = 1)\n",
    "        \n",
    "        line = a.plot(selected_mean)\n",
    "        \n",
    "        x_data = np.arange((selected_mean).shape[0])\n",
    "        \n",
    "        \n",
    "        a.fill_between(x_data ,selected_mean - std, selected_mean + std, alpha = 0.1 )\n",
    "        a.legend(exp_conds)\n",
    "        \n",
    "handles, labels = a.get_legend_handles_labels()\n",
    "fig_compr_means.legend(handles, labels, loc='lower center')\n",
    "plt.show()\n",
    "    \n",
    "#axes_compr_means.set_title('Means of the high SNR weight trajectory')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "600.8px",
    "left": "35px",
    "top": "353.8px",
    "width": "312.073px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
