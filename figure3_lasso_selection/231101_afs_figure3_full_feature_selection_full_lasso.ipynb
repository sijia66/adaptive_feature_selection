{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this simulation\n",
    "\n",
    "we wanted to check that with full matrix works with lasso regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.470529Z",
     "start_time": "2023-11-25T00:09:15.863736Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maopy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweights\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aopy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import aopy\n",
    "import sklearn\n",
    "from weights import *\n",
    "from weights_linear_regression import calc_R2_with_sim_C\n",
    "from afs_plotting import subplots_with_labels\n",
    "\n",
    "# so that we write in latex\n",
    "from matplotlib import rc\n",
    "\n",
    "# rc('font', **{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=False)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "sns.set_context('paper')\n",
    "sns.set_theme(\"paper\", font=\"Arial\")\n",
    "\n",
    "save_to_gdrive = False # this is done through the gdrive's mapping to the local file system\n",
    "gdrive_directory = '/home/aolab/gdrive/Projects/Feature Selection/Figures/'\n",
    "dpi_value = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.474400Z",
     "start_time": "2023-11-25T00:09:17.474386Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dump_folder = \\\n",
    "        '/home/aolab/sijia/data/figure3_lasso/'\n",
    "\n",
    "ROUND_DECIMALS = 3\n",
    "\n",
    "\n",
    "random_seed =7\n",
    "n_neurons = 128\n",
    "\n",
    "# clda setup \n",
    "rho = 0.5\n",
    "batchlen = 100\n",
    "feature_selection_method = \"joint_convex\"\n",
    "encoder_change_mode = \"shuffle_rows\"\n",
    "# encoder_change_mode = \"change_to_zeros\"\n",
    "\n",
    "# noises = np.arange(9)\n",
    "# noises = np.exp2(noises)\n",
    "noises = [32]\n",
    "noise = 32\n",
    "\n",
    "# we set up the neural populations\n",
    "mean_first_peak = 50\n",
    "mean_second_peak = 100\n",
    "std_of_peaks = 3\n",
    "\n",
    "# feature_selection_method \n",
    "feature_selection_method = \"full\"\n",
    "exp_conds = []\n",
    "\n",
    "# uncomment out this to compare to the full feature selection method\n",
    "# exp_conds_wo = [f'{feature_selection_method}_{1.0}_{random_seed}_noise_{noise}_{n_neurons}_{mean_second_peak}_{std_of_peaks}_clda_rho_{rho}_batchlen_{batchlen}_{encoder_change_mode}' ]\n",
    "# exp_conds += exp_conds_wo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#smoothness_array =  np.arange(0.025, 0.15, 0.025)\n",
    "smoothness_array = [0.05]\n",
    "num_lags_array = [3]\n",
    "num_of_features = 32 # specify how many features we want to use, or None\n",
    "\n",
    "encoder_change_modes = [\"same\", \"shuffle_rows\"]\n",
    "\n",
    "##### lasso\n",
    "lasso_alphas = [10]\n",
    "lasso_thresholds = [1]\n",
    "for encoder_change_mode in encoder_change_modes:\n",
    "    more_exp_conds = []\n",
    "    for lasso_alpha in lasso_alphas:\n",
    "        for lasso_threshold in lasso_thresholds:\n",
    "            more_exp_conds.append(f'lasso_{1.0}_{random_seed}_noise_{noise}_{n_neurons}_{mean_second_peak}_{std_of_peaks}_clda_rho_{rho}_batchlen_{batchlen}_lasso_alpha_{lasso_alpha}_lasso_threshold_{lasso_threshold}_{encoder_change_mode}')\n",
    "    exp_conds += more_exp_conds\n",
    "\n",
    "    ##### last one is with the full feature selection\n",
    "    more_exp_conds = []\n",
    "    updater_type = \"smooth_batch_with_full_feature\"\n",
    "    for lasso_alpha in lasso_alphas:\n",
    "        for lasso_threshold in lasso_thresholds:\n",
    "            more_exp_conds.append(f'lasso_{1.0}_{random_seed}_noise_{noise}_{n_neurons}_{mean_second_peak}_{std_of_peaks}_clda_rho_{rho}_batchlen_{batchlen}_lasso_alpha_{lasso_alpha}_lasso_threshold_{lasso_threshold}_{encoder_change_mode}')\n",
    "\n",
    "    # add smooth batch with full batch\n",
    "    UPDATER_TYPE = \"smooth_batch_with_full_feature\"\n",
    "    if  UPDATER_TYPE != 'smooth_batch':\n",
    "        for i, exp_cond in enumerate(more_exp_conds):\n",
    "            more_exp_conds[i] = exp_cond + f'_{UPDATER_TYPE}'\n",
    "\n",
    "    exp_conds += more_exp_conds\n",
    "\n",
    "# feature_selection_schemes = ['lasso threshold 0','lasso threshold 1', 'lasso threshold 2', 'lasso threshold 2.5',\n",
    "#                              'lasso threshold 0 w/ full matrix','lasso w/ full matrix threshold 1', 'lasso w/ full matrix threshold 2', 'lasso w/ full matrix threshold 2.5']\n",
    "\n",
    "feature_selection_schemes = ['w/o tracking ',\n",
    "                             'w/ tracking ',\n",
    "                             'w/o tracking',\n",
    "                             'w/ tracking',]\n",
    "\n",
    "\n",
    "print(\"the folder at which data is located:\")\n",
    "print(data_dump_folder)\n",
    "for m,e in zip(feature_selection_schemes, exp_conds):print(m, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.476214Z",
     "start_time": "2023-11-25T00:09:17.476202Z"
    }
   },
   "outputs": [],
   "source": [
    "from afs_files import load_feature_selection_files, load_and_convert_clda_pickle_files\n",
    "(exp_data_all, exp_metadata_all) = load_feature_selection_files(data_dump_folder, exp_conds)\n",
    "clda_data_all = load_and_convert_clda_pickle_files(data_dump_folder, exp_conds)\n",
    "print(f'we collected {len(exp_data_all)} number of experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check feature selection strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot selected features across feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.477261Z",
     "start_time": "2023-11-25T00:09:17.477249Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib \n",
    "from afs_plotting import plot_feature_selection\n",
    "\n",
    "if len(exp_data_all) ==  1:\n",
    "    plot_feature_selection(exp_data_all[0]['feature_selection']['feat_set'])\n",
    "else:\n",
    "    \n",
    "    num_columns = len(exp_data_all)\n",
    "\n",
    "    fig_feat_activity, ax_feat_activity = plt.subplots(2, 3, \n",
    "                                                    sharey = True,\n",
    "                                                    figsize = (12, 8))\n",
    "\n",
    "    for i, (e, a) in enumerate(zip(exp_data_all,  ax_feat_activity.flatten())):\n",
    "        plot_feature_selection(e['feature_selection']['feat_set'], ax = a)\n",
    "        \n",
    "        a.set_title(feature_selection_schemes[i])\n",
    "\n",
    "fig_feat_activity.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the encoder change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.478642Z",
     "start_time": "2023-11-25T00:09:17.478631Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_encoder_weight_change(sim_c, new_sim_c=None,\n",
    "                                     include_new_sim_c=False, nnum_of_repeats_before=30, num_of_repeats_after=30):\n",
    "    good_features_initial = (np.linalg.norm(sim_c, axis=1))\n",
    "    if include_new_sim_c:\n",
    "        good_features_after_shuffled = (np.linalg.norm(new_sim_c, axis=1))\n",
    "    else:\n",
    "        good_features_after_shuffled = good_features_initial\n",
    "\n",
    "    old_features_before_shuffled_repeat = np.repeat(good_features_initial[:, np.newaxis],\n",
    "                                                    nnum_of_repeats_before, axis = 1)\n",
    "    new_features_after_shuffled_repeat = np.repeat(good_features_after_shuffled[:, np.newaxis],\n",
    "                                                    num_of_repeats_after, axis = 1)\n",
    "\n",
    "    encoder_weight_change = np.concatenate((old_features_before_shuffled_repeat,\n",
    "                                            new_features_after_shuffled_repeat), axis = 1)\n",
    "    return encoder_weight_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.479496Z",
     "start_time": "2023-11-25T00:09:17.479485Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "new_sim_c = exp_data_all[0]['feature_selection']['new_sim_c']\n",
    "sim_c = exp_data_all[0]['feature_selection']['sim_C']\n",
    "encoder_weight_change_stationary = calculate_encoder_weight_change(sim_c,\n",
    "                                        include_new_sim_c=False, nnum_of_repeats_before=30, num_of_repeats_after=90)\n",
    "\n",
    "new_sim_c = exp_data_all[2]['feature_selection']['new_sim_c']\n",
    "sim_c = exp_data_all[2]['feature_selection']['sim_C']\n",
    "encoder_weight_change_shuffle = calculate_encoder_weight_change(sim_c, new_sim_c=new_sim_c,\n",
    "                                        include_new_sim_c=True, nnum_of_repeats_before=30, num_of_repeats_after=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.480707Z",
     "start_time": "2023-11-25T00:09:17.480696Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(encoder_weight_change_shuffle, aspect = 'auto')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.481923Z",
     "start_time": "2023-11-25T00:09:17.481912Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(exp_data_all) ==  1:\n",
    "    plot_feature_selection(exp_data_all[0]['feature_selection']['feat_set'])\n",
    "else:\n",
    "    \n",
    "    num_columns = len(exp_data_all)\n",
    "\n",
    "    fig_feat_activity, ax_encoder_feat_activity = plt.subplots(2, 3, \n",
    "                                                    sharey = True,\n",
    "                                                    figsize = (12, 8))\n",
    "    \n",
    "    ax_encoder_feat_activity[0, 0].imshow(encoder_weight_change_stationary, cmap = 'gray',\n",
    "                                          aspect = 'auto')\n",
    "    ax_encoder_feat_activity[0, 0].grid(False)\n",
    "    ax_encoder_feat_activity[0, 0].set_ylabel('neurons')\n",
    "\n",
    "    ax_encoder_feat_activity[1, 0].imshow(encoder_weight_change_shuffle, cmap = 'gray',\n",
    "                                          aspect = 'auto')\n",
    "    ax_encoder_feat_activity[1, 0].grid(False)\n",
    "    ax_encoder_feat_activity[1, 0].set_ylabel('neurons')\n",
    "    \n",
    "    ax_feat_activity = ax_encoder_feat_activity[:, 1:]\n",
    "\n",
    "    for i, (e, a) in enumerate(zip(exp_data_all,  ax_feat_activity.flatten())):\n",
    "        plot_feature_selection(e['feature_selection']['feat_set'], ax = a)\n",
    "        \n",
    "        a.set_title(feature_selection_schemes[i])\n",
    "\n",
    "fig_feat_activity.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.483344Z",
     "start_time": "2023-11-25T00:09:17.483333Z"
    }
   },
   "outputs": [],
   "source": [
    "# next question I ask,  how many features are being selected, anyway? \n",
    "num_features_exp_by_batch = []\n",
    "\n",
    "selected_feature_batches = [exp_data_all[i]['feature_selection']['feat_set'] for i in range(len(exp_data_all))]\n",
    "\n",
    "for i,e in enumerate(exp_data_all):\n",
    "\n",
    "    active_set = e['feature_selection']['feat_set']\n",
    "\n",
    "    num_features_over_batch = np.sum(active_set, axis = 1)\n",
    "    num_features_exp_by_batch.append(num_features_over_batch.copy())\n",
    "\n",
    "num_features_exp_by_batch = np.array(num_features_exp_by_batch)\n",
    "selected_feature_batches = np.array(selected_feature_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.484658Z",
     "start_time": "2023-11-25T00:09:17.484647Z"
    }
   },
   "outputs": [],
   "source": [
    "print(selected_feature_batches.shape)\n",
    "\n",
    "selected_features_conds_by_feature_batches = np.moveaxis(selected_feature_batches, 1, 2)\n",
    "\n",
    "\n",
    "smoothness_conds_by_batch = \\\n",
    "calculate_feature_smoothness_multiple_conditions(selected_features_conds_by_feature_batches, \n",
    "                                                 mode = \"incremental\")\n",
    "\n",
    "print(smoothness_conds_by_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.485709Z",
     "start_time": "2023-11-25T00:09:17.485698Z"
    }
   },
   "outputs": [],
   "source": [
    "#sns.set_palette(\"Blues\")\n",
    "\n",
    "ax  = sns.lineplot(data = smoothness_conds_by_batch.T, dashes=False)\n",
    "# ax.set_xticklabels(sparsity_array)\n",
    "ax.set_title(\"\")\n",
    "\n",
    "# put legend outside of the plot\n",
    "\n",
    "ax.legend(feature_selection_schemes, bbox_to_anchor=(1.05, 1), loc=2)\n",
    "smoothness_conds_by_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.486521Z",
     "start_time": "2023-11-25T00:09:17.486510Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming smoothness_conds_by_batch is a numpy array with shape (n_batches, n_features)\n",
    "window_size = 6\n",
    "weights = np.ones(window_size) / window_size\n",
    "smoothness_conds_by_batch_ma = np.apply_along_axis(lambda x: np.convolve(x, weights, mode='valid'), \n",
    "                                                   axis=1,\n",
    "                                                   arr=smoothness_conds_by_batch)\n",
    "\n",
    "ax  = sns.lineplot(data = smoothness_conds_by_batch_ma.T, dashes=False)\n",
    "# ax.set_xticklabels(sparsity_array)\n",
    "ax.set_title(\"\")\n",
    "\n",
    "# put legend outside of the plot\n",
    "\n",
    "ax.legend(feature_selection_schemes, bbox_to_anchor=(1.05, 1), loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.487279Z",
     "start_time": "2023-11-25T00:09:17.487269Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_num_features, ax_num_features = plt.subplots()\n",
    "\n",
    "ax_num_features.plot(num_features_exp_by_batch.T)\n",
    "\n",
    "ax_num_features.set_xlabel('Batch number')\n",
    "ax_num_features.set_ylabel('Number of features')\n",
    "\n",
    "ax_num_features.legend(feature_selection_schemes, loc=(1.04,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the relevance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.488110Z",
     "start_time": "2023-11-25T00:09:17.488098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calc_R2_with_sim_C( spike_counts_batch,intended_velocities, C_mat, active_set, \n",
    "                       remove_first_and_last_Batch = True, \n",
    "                       c_mat_remove_first_batch = True, \n",
    "                       select_only_vel_states = True,\n",
    "                       select_features_with_active_set = False,\n",
    "                       debug = True):\n",
    "    \n",
    "    \n",
    "        # then we iterate through the batch sort of thing.\n",
    "    NUM_LEARNER_BATCHES = intended_velocities.shape[0]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"intended_velocities\", intended_velocities.shape)\n",
    "        print(\"spike_counts_batch\", len(spike_counts_batch))\n",
    "        print(\"C_mat\", C_mat.shape)\n",
    "        print(\"active_set\", active_set.shape)\n",
    "    \n",
    "    if remove_first_and_last_Batch:\n",
    "        active_set = active_set[1:-1, :]\n",
    "    if c_mat_remove_first_batch:\n",
    "        C_mat = C_mat[1:, :, : ]\n",
    "        \n",
    "    if select_only_vel_states:\n",
    "        C_mat = C_mat[:,:,(X_VEL_STATE, Y_VEL_STATE,CONST_STATE)]\n",
    "        \n",
    "    \n",
    "    if debug:\n",
    "        print(\"intended_velocities\", intended_velocities.shape)\n",
    "        print(\"spike_counts_batch\", len(spike_counts_batch))\n",
    "        print(\"C_mat\", C_mat.shape)\n",
    "        print(\"active_set\", active_set.shape)\n",
    "        \n",
    "\n",
    "    \n",
    "    R_2_over_batch = []\n",
    "    \n",
    "    for i in range(NUM_LEARNER_BATCHES):\n",
    "        \n",
    "        batch_vel =  intended_velocities[i,:,:]\n",
    "        \n",
    "        # check if we get the data from the list or the np.ndarray\n",
    "        if type(spike_counts_batch) == list:\n",
    "            batch_spike_counts = spike_counts_batch[i]\n",
    "        else:\n",
    "            batch_spike_counts = spike_counts_batch[i,:,:]\n",
    "        \n",
    "        #  we can only compare to what's being used in the calculation\n",
    "        if select_features_with_active_set:\n",
    "            if debug: print(batch_spike_counts.shape)\n",
    "            batch_spike_counts = batch_spike_counts[active_set[i,:],:].T\n",
    "        else:\n",
    "            batch_spike_counts = batch_spike_counts[: ,:].T\n",
    "        \n",
    "        batch_c_mat = C_mat[i,:,:]\n",
    "        \n",
    "        selected_c_mat = batch_c_mat[active_set[i,:],:]\n",
    "        \n",
    "\n",
    "        estimated_spike_counts = selected_c_mat @ batch_vel\n",
    "        \n",
    "        score = r2_score(batch_spike_counts, estimated_spike_counts.T)\n",
    "        \n",
    "        R_2_over_batch.append(score)\n",
    "        \n",
    "    return R_2_over_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.489308Z",
     "start_time": "2023-11-25T00:09:17.489296Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "R_2_over_batches_all_exp = []\n",
    "\n",
    "\n",
    "X_VEL_STATE = 3\n",
    "Y_VEL_STATE = 5\n",
    "CONST_STATE = 6\n",
    "\n",
    "for exp_index in range(len(exp_data_all)):\n",
    "    # intended_kin = exp_data_all[exp_index]['bmi3d_clda']['intended_kin']\n",
    "    # spike_counts_batch = exp_data_all[exp_index]['bmi3d_clda']['spike_counts_batch']\n",
    "    \n",
    "    try:\n",
    "        intended_kin = clda_data_all[exp_index]['intended_kin']\n",
    "        spike_counts_batch = clda_data_all[exp_index]['spike_counts_batch']\n",
    "\n",
    "        intended_kin = np.array(intended_kin)\n",
    "        print(intended_kin.shape)\n",
    "\n",
    "        intended_velocities = intended_kin[:, [X_VEL_STATE, Y_VEL_STATE, CONST_STATE],:]\n",
    "        # # get C_mat\n",
    "        feature_selection_data = exp_data_all[exp_index]['feature_selection']\n",
    "        C_mat = feature_selection_data[\"C_mat\"]\n",
    "        feat_set = feature_selection_data[\"feat_set\"]\n",
    "\n",
    "        # # calculate R_2 over batches\n",
    "        R_2_over_batches = calc_R2_with_sim_C(spike_counts_batch, \n",
    "                                            intended_velocities,\n",
    "                                            C_mat, feat_set, debug = False)\n",
    "        \n",
    "        # #save  the results\n",
    "        R_2_over_batches_all_exp.append(R_2_over_batches)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"KeyError: {e}not found in data.\")\n",
    "    \n",
    "    # #save  the results\n",
    "    # R_2_over_batches_all_exp.append(R_2_over_batches)\n",
    "    \n",
    "    print(exp_index)\n",
    "    \n",
    "R_2_over_batches_all_exp = np.array(R_2_over_batches_all_exp)\n",
    "R_2_over_batches_all_exp_gap = R_2_over_batches_all_exp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.490135Z",
     "start_time": "2023-11-25T00:09:17.490124Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply moving average to the first axis\n",
    "window_size = 6\n",
    "weights = np.ones(window_size) / window_size\n",
    "R_2_over_batches_all_exp_gap_ma = np.apply_along_axis(lambda x: np.convolve(x, weights, mode='valid'), \n",
    "                                                   axis=0,\n",
    "                                                   arr=R_2_over_batches_all_exp_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.491941Z",
     "start_time": "2023-11-25T00:09:17.491927Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(R_2_over_batches_all_exp_gap_ma)\n",
    "plt.legend(feature_selection_schemes, loc=(1.04,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Behaviour comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count how many rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.493153Z",
     "start_time": "2023-11-25T00:09:17.493141Z"
    }
   },
   "outputs": [],
   "source": [
    "fps = 60\n",
    "\n",
    "reward_rate_all = list()\n",
    "window_time_stamps_all = list()\n",
    "NUM_EXP = len(exp_data_all)\n",
    "\n",
    "total_rewards_all = list()\n",
    "\n",
    "for i in range(NUM_EXP):\n",
    "\n",
    "    time_stamps = exp_data_all[i]['events']['time'] / fps\n",
    "    events = exp_data_all[i]['events']['event']\n",
    "    \n",
    "    \n",
    "    num_rewards = np.count_nonzero(events == b'REWARD')\n",
    "\n",
    "    (reward_rate, window_time_stamps) = aopy.analysis.calc_running_event_rate(b'REWARD', events, time_stamps, \n",
    "                                                                window_size= 120,\n",
    "                                                                 window_step= 30)\n",
    "    reward_rate_all.append(reward_rate)\n",
    "    window_time_stamps_all.append(window_time_stamps)\n",
    "    total_rewards_all.append(num_rewards)\n",
    "\n",
    "\n",
    "window_stamps_all = np.array(window_time_stamps_all)\n",
    "reward_rate_all = np.array(reward_rate_all) \n",
    "reward_rate_all = reward_rate_all.reshape((NUM_EXP,-1))\n",
    "window_stamps_all = window_stamps_all.reshape((NUM_EXP,-1))\n",
    "\n",
    "total_rewards_all = np.array(total_rewards_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.494128Z",
     "start_time": "2023-11-25T00:09:17.494117Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'red']\n",
    "\n",
    "plt.plot(window_time_stamps, reward_rate_all.T)\n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel(r'Reward rate (rewards/min)')\n",
    "# put the legend outside of the figure\n",
    "plt.legend(feature_selection_schemes, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT: summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.495304Z",
     "start_time": "2023-11-25T00:09:17.495293Z"
    }
   },
   "outputs": [],
   "source": [
    "# make the figure according to the plan\n",
    "summary_figure, summary_axes = subplots_with_labels(2, 5,\n",
    "                                            figsize = (6.5, 4.5 ))\n",
    "\n",
    "# specify the line styles\n",
    "line_styles = ['--', '-', '--', '-']\n",
    "line_colors = ['blue', 'blue', 'orange', 'orange']\n",
    "legends = ['w/o Tracking', 'w/ Tracking']\n",
    "\n",
    "stationary_shuffling_indices = [[0,1], [2,3]]\n",
    "\n",
    "# top left, is the ground truth for the staionary encoder\n",
    "# we don't have that yet\n",
    "summary_axes[0,0].imshow(encoder_weight_change_stationary, cmap = 'gray',\n",
    "                                            aspect = 'auto')\n",
    "summary_axes[0,0].grid(False)\n",
    "summary_axes[0,0].set_ylabel('neurons')\n",
    "summary_axes[0,0].set_title('Stationary')\n",
    "\n",
    "# then the shuffling encoder case\n",
    "summary_axes[1,0].imshow(encoder_weight_change_shuffle, cmap = 'gray',\n",
    "                                          aspect = 'auto')\n",
    "summary_axes[1,0].grid(False)\n",
    "summary_axes[1,0].set_ylabel('neurons')\n",
    "summary_axes[1,0].set_title('Shuffling')\n",
    "summary_axes[1,0].set_xlabel('Batch number')\n",
    "\n",
    "\n",
    "# top middle and right is the strategy for the stationary encoder\n",
    "\n",
    "plot_feature_selection(exp_data_all[0]['feature_selection']['feat_set'], ax = summary_axes[0,1])\n",
    "plot_feature_selection(exp_data_all[1]['feature_selection']['feat_set'], ax = summary_axes[0,2])\n",
    "summary_axes[0,1].set_xlabel('')\n",
    "summary_axes[0,2].set_xlabel('')\n",
    "\n",
    "summary_axes[0,1].set_title(feature_selection_schemes[2])\n",
    "summary_axes[0,2].set_title(feature_selection_schemes[3])\n",
    "\n",
    "# middle middle and right is the strategy for the shuffle encoder\n",
    "plot_feature_selection(exp_data_all[2]['feature_selection']['feat_set'], ax = summary_axes[1,1])\n",
    "plot_feature_selection(exp_data_all[3]['feature_selection']['feat_set'], ax = summary_axes[1,2])\n",
    "summary_axes[1,1].set_title(feature_selection_schemes[2])\n",
    "summary_axes[1,2].set_title(feature_selection_schemes[3])\n",
    "summary_axes[1,1].set_xlabel('Batch Number')\n",
    "summary_axes[1,2].set_xlabel('Batch Number')\n",
    "\n",
    "\n",
    "# two right figures are smoothness and reward rate comparisions\n",
    "summary_axes[0,3].plot(smoothness_conds_by_batch_ma[stationary_shuffling_indices[0], :].T, \n",
    "                       label = legends)\n",
    "summary_axes[1,3].plot(smoothness_conds_by_batch_ma[stationary_shuffling_indices[1],:].T)\n",
    "\n",
    "summary_axes[1,3].set_xlabel('Batch number')\n",
    "summary_axes[0,3].set_ylabel('Smoothness')\n",
    "summary_axes[1,3].set_ylabel('Smoothness')\n",
    "\n",
    "\n",
    "# then the reward rate\n",
    "summary_axes[0,4].plot(window_time_stamps / 60, \n",
    "                       reward_rate_all[stationary_shuffling_indices[0],:].T)\n",
    "\n",
    "summary_axes[1,4].plot(window_time_stamps / 60,\n",
    "                          reward_rate_all[stationary_shuffling_indices[1],:].T)\n",
    "summary_axes[1,4].set_xlabel('Time (min)')\n",
    "summary_axes[0,4].set_ylabel('Reward rate \\n (rewards/min)')\n",
    "summary_axes[1,4].set_ylabel('Reward rate \\n (rewards/min)')\n",
    "\n",
    "\n",
    "# put the legend outside of the figure\n",
    "lgd = summary_figure.legend(bbox_to_anchor=(0.6, -.01), ncol = 2, \n",
    "                         loc=2, borderaxespad=0.)\n",
    "summary_figure.subplots_adjust(bottom=0.2)\n",
    "\n",
    "summary_figure.tight_layout()\n",
    "summary_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we transform into the new format of two columns for stationary and shuffling encoder, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.496299Z",
     "start_time": "2023-11-25T00:09:17.496288Z"
    }
   },
   "outputs": [],
   "source": [
    "from afs_plotting import concatenate_encoder_weights_feature_sets\n",
    "\n",
    "# concatennate encoder weights and feature sets work for the first and last exp_data_all\n",
    "encoder_weights_features_sets_stationary = concatenate_encoder_weights_feature_sets(\n",
    "    encoder_weight_change_stationary, exp_data_all[:2]\n",
    ")\n",
    "\n",
    "encoder_weights_features_sets_shuffle = concatenate_encoder_weights_feature_sets(\n",
    "    encoder_weight_change_shuffle, exp_data_all[2:]\n",
    ")\n",
    "\n",
    "print(encoder_weights_features_sets_stationary.shape)\n",
    "print(encoder_weights_features_sets_shuffle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT the new column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.497067Z",
     "start_time": "2023-11-25T00:09:17.497056Z"
    }
   },
   "outputs": [],
   "source": [
    "num_batches = encoder_weight_change_stationary.shape[0]\n",
    "delta_batch_for_display = 32\n",
    "\n",
    "# make the figure according to the plan\n",
    "summary_figure, summary_axes = subplots_with_labels(3, 2,\n",
    "                                            figsize = (6.5, 4.5 ),\n",
    "                                            label_directions='col_first')\n",
    "\n",
    "# specify the line styles\n",
    "line_styles = ['--', '-', '--', '-']\n",
    "line_colors = ['blue', 'blue', 'orange', 'orange']\n",
    "legends = ['w/o Tracking', 'w/ Tracking']\n",
    "\n",
    "stationary_shuffling_indices = [[0,1], [2,3]]\n",
    "\n",
    "# top left, is the ground truth for the staionary encoder\n",
    "# we don't have that yet\n",
    "summary_axes[0,0].imshow(encoder_weights_features_sets_stationary, cmap = 'gray',\n",
    "                                            aspect = 'auto')\n",
    "summary_axes[0,0].grid(False)\n",
    "summary_axes[0,0].set_ylabel('neurons')\n",
    "\n",
    "summary_axes[0,0].set_xticks(np.arange(0, num_batches, delta_batch_for_display))\n",
    "summary_axes[0,0].set_xticklabels(np.arange(0, num_batches, delta_batch_for_display ))\n",
    "\n",
    "# put three texts  encoder, smooth, unsmooth on top of the first row, evenly spaced\n",
    "ax_feat_activity = summary_axes[0,0]\n",
    "ax_feat_activity.text(0.05, 1.1, 'Encoder', transform=ax_feat_activity.transAxes)\n",
    "ax_feat_activity.text(0.35, 1.1, 'Unsmooth', transform=ax_feat_activity.transAxes)\n",
    "ax_feat_activity.text(0.75, 1.1, 'Smooth', transform=ax_feat_activity.transAxes)\n",
    "\n",
    "\n",
    "# then the shuffling encoder case\n",
    "summary_axes[0,1].imshow(encoder_weights_features_sets_shuffle, cmap = 'gray',\n",
    "                                          aspect = 'auto')\n",
    "summary_axes[0,1].grid(False)\n",
    "summary_axes[0,1].set_ylabel('neurons')\n",
    "summary_axes[0,1].set_xlabel('Batch number')\n",
    "summary_axes[0,1].set_xticks(np.arange(0, num_batches, delta_batch_for_display))\n",
    "summary_axes[0,1].set_xticklabels(np.arange(0, num_batches, delta_batch_for_display ))\n",
    "\n",
    "# put three texts  encoder, smooth, unsmooth on top of the first row, evenly spaced\n",
    "ax_feat_activity = summary_axes[0,1]\n",
    "ax_feat_activity.text(0.05, 1.1, 'Encoder', transform=ax_feat_activity.transAxes)\n",
    "ax_feat_activity.text(0.35, 1.1, 'Unsmooth', transform=ax_feat_activity.transAxes)\n",
    "ax_feat_activity.text(0.75, 1.1, 'Smooth', transform=ax_feat_activity.transAxes)\n",
    "\n",
    "# two right figures are smoothness and reward rate comparisions\n",
    "summary_axes[1,0].plot(smoothness_conds_by_batch_ma[stationary_shuffling_indices[0], :].T, \n",
    "                       label = legends)\n",
    "summary_axes[1,1].plot(smoothness_conds_by_batch_ma[stationary_shuffling_indices[1],:].T)\n",
    "\n",
    "summary_axes[1,0].set_ylabel('Smoothness')\n",
    "\n",
    "\n",
    "# then the reward rate\n",
    "summary_axes[2,0].plot(window_time_stamps / 60, \n",
    "                       reward_rate_all[stationary_shuffling_indices[0],:].T)\n",
    "\n",
    "summary_axes[2,1].plot(window_time_stamps / 60,\n",
    "                          reward_rate_all[stationary_shuffling_indices[1],:].T)\n",
    "summary_axes[2,0].set_xlabel('Time (min)')\n",
    "summary_axes[2,1].set_xlabel('Time (min)')\n",
    "summary_axes[2,0].set_ylabel('Reward rate \\n (rewards/min)')\n",
    "summary_axes[2,1].set_xlabel('Time (min)')\n",
    "\n",
    "# put the legend outside of the figure\n",
    "lgd = summary_figure.legend(bbox_to_anchor=(0.6, -.01), ncol = 2, \n",
    "                         loc=2, borderaxespad=0.)\n",
    "summary_figure.subplots_adjust(bottom=0.2)\n",
    "\n",
    "summary_figure.tight_layout()\n",
    "summary_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:09:17.497918Z",
     "start_time": "2023-11-25T00:09:17.497906Z"
    }
   },
   "outputs": [],
   "source": [
    "if gdrive_directory:\n",
    "    summary_figure.savefig(gdrive_directory + 'figure3_lasso_encoder_change.pdf', dpi = dpi_value,\n",
    "                            bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    summary_figure.savefig(gdrive_directory + 'figure3_lasso_encoder_change.png', \n",
    "                           bbox_extra_artists=(lgd,),dpi = dpi_value, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "ea3bd0d464f68af5ec83035eebbd8b594045b41945d727c3346e6ab045406918"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "600.8px",
    "left": "35px",
    "top": "353.8px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
